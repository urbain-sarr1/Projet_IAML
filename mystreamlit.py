import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler
import shap

# Configuration du titre du dashboard
st.set_page_config(page_title="Analyse de la R√©siliation Client", page_icon="üîç", layout="wide")

# Titre
st.title("üîç Dashboard Interactif - Analyse de la R√©siliation Client")

# 1. Chargement des donn√©es
@st.cache
def load_data():
    return pd.read_csv("churn_clients.csv")

df = load_data()

# 2. Aper√ßu des donn√©es
st.subheader("1. Aper√ßu des donn√©es")
st.write(f"Nombre total de clients : {df.shape[0]}")
st.write(f"Colonnes disponibles : {list(df.columns)}")

# Affichage dynamique de l'aper√ßu des donn√©es
num_rows = st.slider("S√©lectionnez le nombre de lignes √† afficher", 5, 50, 10)
st.dataframe(df.head(num_rows))

# 3. S√©lection des caract√©ristiques
st.subheader("2. S√©lectionnez les caract√©ristiques √† analyser")

# Choix des variables √† afficher dans la visualisation
col1, col2 = st.columns(2)
with col1:
    selected_feature = st.selectbox("S√©lectionner une caract√©ristique pour la visualisation", df.columns.tolist())

# Visualisation des caract√©ristiques s√©lectionn√©es
st.write(f"**Histogramme de {selected_feature}**")
fig, ax = plt.subplots()
sns.histplot(df[selected_feature].dropna(), kde=True, ax=ax)
st.pyplot(fig)

# 4. Nettoyage et pr√©paration des donn√©es
st.subheader("3. Nettoyage et pr√©paration des donn√©es")

df_clean = df.copy()

# Encodage des variables cat√©gorielles
for col in df_clean.select_dtypes(include='object').columns:
    df_clean[col] = LabelEncoder().fit_transform(df_clean[col].astype(str))

# Suppression des valeurs manquantes
df_clean = df_clean.dropna()

# Mise √† l'√©chelle des donn√©es
scaler = StandardScaler()
X = df_clean.drop("Resilie", axis=1)
y = df_clean["Resilie"]
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# 5. S√©lection d'un mod√®le pour pr√©diction
st.subheader("4. Mod√©lisation et Pr√©diction")

# S√©lection de l'algorithme de pr√©diction
model_option = st.selectbox("Choisissez le mod√®le √† utiliser", ["Arbre de D√©cision", "R√©gression Logistique", "For√™t Al√©atoire"])

if model_option == "Arbre de D√©cision":
    model = DecisionTreeClassifier(random_state=42)
elif model_option == "R√©gression Logistique":
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(random_state=42)
else:
    from sklearn.ensemble import RandomForestClassifier
    model = RandomForestClassifier(random_state=42)

# S√©paration des donn√©es et entra√Ænement
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Affichage des r√©sultats de pr√©diction
st.write("**Rapport de Classification**")
st.text(classification_report(y_test, y_pred))

# 6. Visualisation de la matrice de confusion
st.subheader("5. Matrice de confusion")
fig, ax = plt.subplots()
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Blues", ax=ax)
st.pyplot(fig)

# 7. Explication avec SHAP
st.subheader("6. Explication des Pr√©dictions avec SHAP")
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_scaled)

# Choisir un client pour expliquer la pr√©diction
index = st.slider("Choisissez un client √† analyser", 0, len(X_scaled) - 1, 0)
shap.initjs()

# Affichage de l'importance des variables pour ce client
st.write(f"Pr√©diction pour le client {index}: {'R√©silie' if y_pred[index] == 1 else 'Ne r√©silie pas'}")
shap.force_plot(explainer.expected_value[1], shap_values[1][index], X_scaled.iloc[index])

# 8. Visualisation de l'importance des variables
st.subheader("7. Importance des Variables")
importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)
fig, ax = plt.subplots(figsize=(10, 6))
importances.plot(kind="bar", ax=ax)
plt.title("Importance des Variables")
st.pyplot(fig)

# 9. Visualisation interactive
st.subheader("8. Visualisation Interactive avec des Graphiques Dynamiques")

# S√©lection dynamique des variables
var1 = st.selectbox("S√©lectionnez une variable pour analyser la relation avec la r√©siliation", df.columns)
var2 = st.selectbox("S√©lectionnez une autre variable pour analyser la relation", df.columns)

# Visualisation interactive de la relation entre deux variables
fig, ax = plt.subplots(figsize=(8, 6))
sns.scatterplot(x=df[var1], y=df[var2], hue=df["Resilie"], ax=ax, palette="coolwarm")
st.pyplot(fig)

# Conclusion
st.subheader("9. Conclusion")
st.write("Ce tableau de bord permet une analyse approfondie de la r√©siliation client. Vous pouvez interagir avec les donn√©es pour mieux comprendre les facteurs influen√ßant la d√©cision de r√©siliation.")

