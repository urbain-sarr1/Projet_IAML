import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler
import shap

# Titre du tableau de bord
st.title("üîç Dashboard Analyse de la R√©siliation Client")

# 1. Chargement des donn√©es
df = pd.read_csv("churn_clients.csv")
st.subheader("1. Aper√ßu des donn√©es")
st.write("Nombre de clients :", df.shape[0])
st.write("Colonnes :", list(df.columns))
st.dataframe(df.head())

# 2. Nettoyage des donn√©es
st.subheader("2. Nettoyage des donn√©es")
df_clean = df.copy()

# Encodage des variables cat√©gorielles et nettoyage
for col in df_clean.select_dtypes(include='object').columns:
    df_clean[col] = LabelEncoder().fit_transform(df_clean[col].astype(str))

df_clean = df_clean.dropna()

missing_values = df_clean.isnull().sum().sum()
duplicates = df_clean.duplicated().sum()

st.write("Nombre total de valeurs manquantes :", missing_values)
st.write("Nombre de doublons :", duplicates)

# Standardisation des variables
scaler = StandardScaler()
X = df_clean.drop("Resilie", axis=1)
y = df_clean["Resilie"]
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# 3. Visualisations avec un bouton pour les afficher
st.subheader("3. Visualisations des donn√©es")

# Boutons pour afficher les graphiques
if st.button("Afficher Histogrammes"):
    col1, col2 = st.columns(2)
    with col1:
        st.write("Histogramme des √¢ges")
        fig, ax = plt.subplots()
        sns.histplot(df["Age"].dropna(), bins=20, kde=True, ax=ax)
        st.pyplot(fig)

    with col2:
        st.write("Histogramme des revenus")
        fig, ax = plt.subplots()
        sns.histplot(df["Revenu"].dropna(), bins=20, kde=True, ax=ax)
        st.pyplot(fig)

if st.button("Afficher Corr√©lation"):
    st.write("Corr√©lation entre satisfaction et r√©siliation")
    fig, ax = plt.subplots()
    sns.boxplot(x="Resilie", y="Score_satisfaction", data=df.dropna(subset=["Score_satisfaction"]), ax=ax)
    st.pyplot(fig)

# 4. Entra√Ænement du mod√®le avec un bouton pour afficher les r√©sultats
st.subheader("4. Entra√Ænement du mod√®le")
if st.button("Entra√Æner le mod√®le et afficher les r√©sultats"):
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

    model = DecisionTreeClassifier()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    st.write("Classification Report :")
    st.text(classification_report(y_test, y_pred))

    st.write("Matrice de confusion")
    fig, ax = plt.subplots()
    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Blues", ax=ax)
    st.pyplot(fig)

    # Validation crois√©e
    st.subheader("üìä √âvaluation du mod√®le")
    scoring = {'accuracy': 'accuracy', 'recall': 'recall', 'f1': 'f1', 'roc_auc': 'roc_auc'}
    cv_results = cross_validate(model, X_scaled, y, cv=cv, scoring=scoring)

    score_df = pd.DataFrame({
        'Accuracy': [cv_results['test_accuracy'].mean()],
        'Recall': [cv_results['test_recall'].mean()],
        'F1 Score': [cv_results['test_f1'].mean()],
        'AUC': [cv_results['test_roc_auc'].mean()]
    })
    st.dataframe(score_df.T.rename(columns={0: "Score moyen"}).style.format("{:.4f}"))

# 5. Visualisation de l'importance des variables
if st.button("Afficher Importance des Variables"):
    st.subheader("5. Importance des variables")
    importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)
    fig, ax = plt.subplots(figsize=(8, 5))
    importances.plot(kind="bar", ax=ax)
    plt.title("Importance des variables")
    st.pyplot(fig)

# 6. Explication des pr√©dictions avec SHAP
if st.button("Afficher Explication des Pr√©dictions SHAP"):
    st.subheader("6. Explication des pr√©dictions")
    X_final_df = pd.DataFrame(X_scaled, columns=X.columns)
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X_final_df)

    # S√©lection de l'observation √† analyser
    observation_idx = st.number_input("Choisissez un index client √† analyser", min_value=0, max_value=len(X_final_df) - 1, step=1)

    # Pr√©diction pour cet utilisateur
    prediction = model.predict([X_scaled.iloc[observation_idx]])

    # Affichage de la pr√©diction
    prediction_label = "‚ùå R√©silie" if prediction[0] == 1 else "‚úÖ Ne r√©silie pas"
    st.markdown(f"### Pour l'Observation {observation_idx + 1}, le mod√®le a pr√©dit que le client : **{prediction_label}**")

    # Affichage des valeurs SHAP pour chaque feature
    st.markdown("#### Impact des variables :")
    for feature, shap_value in zip(X_final_df.columns, shap_values[1][observation_idx]):
        direction = "augmente" if shap_value > 0 else "diminue"
        st.markdown(
            f"- **{feature}** : La valeur SHAP est **{shap_value:+.4f}**, ce qui indique que la variable **{feature}** {'augmente' if shap_value > 0 else 'diminue'} la probabilit√© de r√©siliation."
        )

    # Calcul de l'impact total
    expected_value = explainer.expected_value[1]
    impact_total = expected_value + shap_values[1][observation_idx].sum()

    # R√©sum√© global
    st.markdown("#### Conclusion :")
    st.markdown(f"La combinaison de ces impacts donne une sortie mod√®le de **{impact_total:.4f}**.")

