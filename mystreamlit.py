import streamlit as st
import pandas as pd
import plotly.express as px
import shap
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
import joblib

# ----------------- Chargement et Pr√©traitement des donn√©es -----------------
@st.cache_data
def load_and_preprocess_data():
    # Remplace le chemin par le fichier CSV contenant tes donn√©es
    data = pd.read_csv("churn_clients.csv")  # Assure-toi que le fichier est dans le bon r√©pertoire
    return data

data = load_and_preprocess_data()

# ----------------- Pr√©traitement pour le mod√®le -----------------
st.sidebar.title("Filtres")
anciennete = st.sidebar.slider("Anciennet√© (mois)", int(data['Anciennete'].min()), int(data['Anciennete'].max()))
frequence = st.sidebar.slider("Fr√©quence d'utilisation", float(data['Frequence_utilisation'].min()), float(data['Frequence_utilisation'].max()))
score = st.sidebar.slider("Score de satisfaction", float(data['Score_satisfaction'].min()), float(data['Score_satisfaction'].max()))

filtered_data = data[
    (data['Anciennete'] >= anciennete) &
    (data['Frequence_utilisation'] >= frequence) &
    (data['Score_satisfaction'] >= score)
]

# ----------------- Entra√Ænement du mod√®le KMeans -----------------
X = filtered_data[['Anciennete', 'Frequence_utilisation', 'Score_satisfaction']]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kmeans = KMeans(n_clusters=3, random_state=42)
filtered_data['Cluster'] = kmeans.fit_predict(X_scaled)

# ----------------- Entra√Ænement du mod√®le pour SHAP -----------------
# Pour l'explication SHAP, utilisons un arbre de d√©cision
y = [1 if x < 3 else 0 for x in filtered_data['Score_satisfaction']]  # Simplification : r√©siliation si Score < 3

clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_scaled, y)

# Calcul de l'explainer SHAP
explainer = shap.TreeExplainer(clf)
shap_values = explainer.shap_values(X_scaled)

# ----------------- Dashboard -----------------
st.title("üìä Dashboard Clients - R√©siliations et Clustering")

st.markdown("Analyse interactive des comportements clients pour identifier les motifs de r√©siliation.")

st.subheader("üìå Donn√©es filtr√©es")
st.write(f"Nombre de clients : {filtered_data.shape[0]}")
st.dataframe(filtered_data.head())

# ----------------- Clustering -----------------
st.subheader("üß† Clustering des clients (KMeans)")

fig_cluster = px.scatter_3d(filtered_data, 
                            x='Anciennete', y='Frequence_utilisation', z='Score_satisfaction',
                            color='Cluster', title="Clustering 3D des clients")
st.plotly_chart(fig_cluster)

# ----------------- SHAP -----------------
st.subheader("üìà Explication des R√©siliations avec SHAP")

client_id = st.selectbox("Choisir un client √† expliquer :", filtered_data.index)
client_data = filtered_data.loc[[client_id]][['Anciennete', 'Frequence_utilisation', 'Score_satisfaction']]

shap_value_client = shap_values[1][client_id]  # 1 pour la classe 'r√©sili√©' (si Score < 3)

st.markdown("### Contribution des variables")
fig_shap = shap.plots._waterfall.waterfall_legacy(explainer.expected_value[1], shap_value_client, client_data.iloc[0], show=False)
st.pyplot(fig_shap)

# ----------------- R√©sum√© -----------------
st.subheader("üìå R√©sum√© du cluster s√©lectionn√©")
selected_cluster = st.selectbox("Choisir un cluster :", sorted(filtered_data['Cluster'].unique()))
cluster_data = filtered_data[filtered_data['Cluster'] == selected_cluster]

st.metric("Taille du cluster", len(cluster_data))
st.metric("Satisfaction moyenne", round(cluster_data['Score_satisfaction'].mean(), 2))
st.metric("Anciennet√© moyenne", round(cluster_data['Anciennete'].mean(), 2))

fig_hist = px.histogram(cluster_data, x='Score_satisfaction', nbins=20, title="Distribution de satisfaction dans le cluster")
st.plotly_chart(fig_hist)
